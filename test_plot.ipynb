{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn.metrics import log_loss\n",
    "from decentralized_SGD_logistic import DecentralizedSGDLogistic\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from scipy.special import expit as sigmoid\n",
    "\n",
    "from helpers import plot_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RCV dataset from ChocoSGD Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_logistic(A, y, param,):\n",
    "    m = DecentralizedSGDLogistic(param)\n",
    "    res = m.fit(A, y)\n",
    "    print('{} - score: {1:.4f}'.format(param, m.score(A, y)))\n",
    "    return res, m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n"
     ]
    }
   ],
   "source": [
    "dataset_path = os.path.expanduser('../ChocoSGD/data/rcv1_test.binary.bz2')\n",
    "print('Loading dataset...')\n",
    "A, y = load_svmlight_file(dataset_path)\n",
    "A_p = A[:100000]\n",
    "y_p = y[:100000]\n",
    "y_p = 1*(y_p > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the baseline with SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adirlou/.local/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.97885\n"
     ]
    }
   ],
   "source": [
    "clf = SGDClassifier(loss='log', penalty='l2',alpha =1/A_p.shape[0])\n",
    "clf.fit(A_p, y_p)\n",
    "print(clf.score(A_p, y_p))\n",
    "x_predict = clf.predict(A_p)\n",
    "exact_optimum = log_loss(x_predict, y_p) + (1 / A_p.shape[0]) * np.sum(x_predict**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute with Decentralized SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = 1 / A_p.shape[0]\n",
    "n_features = A_p.shape[1]\n",
    "\n",
    "params_disconnected = Parameters(num_epoch=5, lr_type='bottou',\n",
    "                           initial_lr=10, tau=n_features, regularizer=reg,\n",
    "                           quantization='full', n_machines=128,\n",
    "                           method='plain',topology='complete', estimate='final',\n",
    "                           split_data_random_seed=2, distribute_data=True,\n",
    "                           split_data_strategy='naive')\n",
    "\n",
    "res_disconnected, dec_log = run_logistic(A_p, y_p, params_disconnected)\n",
    "\n",
    "\"\"\"params_ring = dict(name=\"chocosgd-centralized\", num_epoch=5, lr_type='bottou',\n",
    "                           initial_lr=0.2, tau=n_features, regularizer=reg,\n",
    "                           quantization='full', n_cores=10,\n",
    "                           method='plain', topology='centralized', estimate='final',\n",
    "                           split_data_random_seed=2, distribute_data=True,\n",
    "                           split_data_strategy='naive')\n",
    "\n",
    "res_centralized = run_logistic(A_p, y_p, params_ring)\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Higgs Boson Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_logistic(A, y, param, logging=False):\n",
    "    m = DecentralizedSGDLogistic(**param)\n",
    "    list_losses = m.fit(A, y, logging=logging)\n",
    "    if logging:\n",
    "        print()\n",
    "        print('{0} - score: {1:.4f}'.format(param, m.score(A, y)))\n",
    "    return list_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv_data(data_path):\n",
    "    \"\"\"Loads data and returns y (class labels), tX (features) and ids (event ids)\"\"\"\n",
    "    y = np.genfromtxt(data_path, delimiter=\",\", skip_header=1, dtype=str, usecols=1)\n",
    "    x = np.genfromtxt(data_path, delimiter=\",\", skip_header=1)\n",
    "    input_data = x[:, 2:]\n",
    "\n",
    "    # convert class labels from strings to binary (-1,1)\n",
    "    yb = np.ones(len(y))\n",
    "    yb[np.where(y=='b')] = -1\n",
    "\n",
    "    return yb, input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(input_data, mean=False):\n",
    "\n",
    "    #Replace -999 by most frequent value of column\n",
    "    for i in range(input_data.shape[1]):\n",
    "        current_col = input_data[:, i]\n",
    "\n",
    "        if -999.0 in current_col:\n",
    "            indices_to_change = (current_col == -999.0)\n",
    "            if mean:\n",
    "                curr_mean = np.mean(current_col[~indices_to_change])\n",
    "                current_col[indices_to_change] = curr_mean\n",
    "            else:\n",
    "                (values,counts) = np.unique(current_col[~indices_to_change], return_counts=True)\n",
    "                ind=np.argmax(counts)\n",
    "                current_col[indices_to_change] = values[ind] if len(values) > 0 else 0\n",
    "\n",
    "    return input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(x):\n",
    "    \"\"\"Standardize the given data\"\"\"\n",
    "    means = x.mean(0)\n",
    "    stds = x.std(0)\n",
    "    return (x - means)/stds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, A = load_csv_data('train.csv')\n",
    "A = standardize(clean(A, True))\n",
    "y = 1 *(y > 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the baseline with SGD classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.743044\n",
      "Final loss: 0.5040570282830276\n"
     ]
    }
   ],
   "source": [
    "# Fit a SGD\n",
    "clf = SGDClassifier(loss='log', penalty='l2',alpha =1/A.shape[0], tol=1e-4, n_jobs=1)\n",
    "clf.fit(A, y)\n",
    "\n",
    "accuracy = clf.score(A, y)\n",
    "optimum_x = clf.predict_proba(A)[:, 1]\n",
    "\n",
    "# Optimal loss, useful for plots\n",
    "optimum_loss = (-(y.T.dot(np.log(optimum_x)) + (1 - y).T.dot(np.log(1 - optimum_x))) / A.shape[0])\n",
    "\n",
    "print('Accuracy:', accuracy)\n",
    "print('Final loss:', optimum_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing with Decentralized SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of indices: 512\n",
      "length of last machine indices: 488\n",
      "\u001b[32mEpoch      Iteration      Time      Loss      Accuracy      \u001b[0m\n",
      "[1/3]      [488/488]      10s       0.7042    0.6848        \u001b[0m\n",
      "[2/3]      [488/488]      20s       0.5971    0.7188        \u001b[0m\n",
      "[3/3]      [488/488]      29s       0.5790    0.7244        \u001b[0m\n",
      "{'num_epoch': 3, 'lr_type': 'bottou', 'initial_lr': 0.05, 'tau': 30, 'regularizer': 4e-06, 'quantization': 'full', 'n_machines': 512, 'method': 'plain', 'topology': 'disconnected', 'estimate': 'final', 'split_data_random_seed': 2, 'distribute_data': True, 'split_data_strategy': 'naive', 'compute_loss_every': 30} - score: 0.7244\n"
     ]
    }
   ],
   "source": [
    "reg = 1 / A.shape[0]\n",
    "n_features = A.shape[1]\n",
    "compute_loss_every = 30\n",
    "params_disconnected = dict(num_epoch=3, lr_type='bottou',\n",
    "                           initial_lr=0.05, tau=n_features, regularizer=reg,\n",
    "                           quantization='full', n_machines=512,\n",
    "                           method='plain', topology='disconnected', estimate='final',\n",
    "                           split_data_random_seed=2, distribute_data=True,\n",
    "                           split_data_strategy='naive', \n",
    "                           compute_loss_every=compute_loss_every)\n",
    "\n",
    "losses_disconnected = run_logistic(A, y, params_disconnected, logging=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Barbell and Path topologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of indices: 512\n",
      "length of last machine indices: 488\n",
      "\u001b[32mEpoch      Iteration      Time      Loss      Accuracy      \u001b[0m\n",
      "[1/5]      [488/488]      10s       0.5829    0.7111        \u001b[0m\n",
      "[2/5]      [488/488]      20s       0.5677    0.7196        \u001b[0m\n",
      "[3/5]      [488/488]      30s       0.5643    0.7233        \u001b[0m\n",
      "[4/5]      [488/488]      39s       0.5631    0.7249        \u001b[0m\n",
      "\n",
      "{'num_epoch': 5, 'lr_type': 'bottou', 'initial_lr': 0.1, 'tau': 30, 'regularizer': 4e-06, 'quantization': 'full', 'n_machines': 512, 'method': 'plain', 'topology': 'barbell', 'estimate': 'final', 'split_data_random_seed': 2, 'distribute_data': True, 'split_data_strategy': 'naive', 'compute_loss_every': 30} - score: 0.7249\n"
     ]
    }
   ],
   "source": [
    "params_barbell = params_disconnected.copy()\n",
    "params_barbell['topology'] = 'barbell'\n",
    "losses_barbell = run_logistic(A, y, params_barbell, logging=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of indices: 512\n",
      "length of last machine indices: 488\n",
      "\u001b[32mEpoch      Iteration      Time      Loss      Accuracy      \u001b[0m\n",
      "[1/5]      [488/488]      10s       0.5864    0.7235        \u001b[0m\n",
      "[2/5]      [488/488]      19s       0.5716    0.7271        \u001b[0m\n",
      "[3/5]      [488/488]      29s       0.5670    0.7297        \u001b[0m\n",
      "[4/5]      [488/488]      39s       0.5648    0.7289        \u001b[0m\n",
      "[5/5]      [488/488]      48s       0.5637    0.7280        \u001b[0m\n",
      "{'num_epoch': 5, 'lr_type': 'bottou', 'initial_lr': 0.1, 'tau': 30, 'regularizer': 4e-06, 'quantization': 'full', 'n_machines': 512, 'method': 'plain', 'topology': 'path', 'estimate': 'final', 'split_data_random_seed': 2, 'distribute_data': True, 'split_data_strategy': 'naive', 'compute_loss_every': 30} - score: 0.7280\n"
     ]
    }
   ],
   "source": [
    "params_path = params_disconnected.copy()\n",
    "params_path['topology'] = 'path'\n",
    "losses_path = run_logistic(A, y, params_path, logging=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'optimum_loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-00b695fba345>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m                                compute_loss_every)\n\u001b[1;32m      3\u001b[0m plot_losses(np.stack((losses_complete, losses_barbell, losses_path)),\n\u001b[0;32m----> 4\u001b[0;31m             \u001b[0miterations_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimum_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimum_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m             labels=[\"Complete\",\"Barbell\", \"Path\"], title=\"Different topologies\")\n",
      "\u001b[0;31mNameError\u001b[0m: name 'optimum_loss' is not defined"
     ]
    }
   ],
   "source": [
    "iterations_indices = np.arange(0, losses_complete.shape[0] * compute_loss_every, \n",
    "                               compute_loss_every)\n",
    "plot_losses(np.stack((losses_complete, losses_barbell, losses_path)),\n",
    "            iterations_indices, optimum_loss=optimum_loss, \n",
    "            labels=[\"Complete\",\"Barbell\", \"Path\"], title=\"Different topologies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
